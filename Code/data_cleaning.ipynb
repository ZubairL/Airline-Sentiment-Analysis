{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "97226ac3-71de-42ac-a708-c24c7d567b03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cd0109b2-933a-45bd-8ea7-0523a6446b0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/tweets.csv')\n",
    "tweets_df.head()\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bdcfe82f-b9cf-4ef7-bc52-8be3054cb4aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "stops = {\"needn't\", 'we', 'our', 'my', 'any', 'few', \"it's\", \"that'll\", 'do', 'hers', 'because', \n",
    "         'yourself', \"haven't\", 'will', 'with', \"ain't\", \"mustn't\", 'these', 'where', 'so', 'all', \n",
    "         'your', 'over', 'themselves', \"should've\", 'about', 'ours', 'they', 'after', \"weren't\", \n",
    "         'by', 'was', 'being', 'before', 'both', 'myself', 'has', 'into', 'as', \"couldn't\", \"we're\",\n",
    "         'ourselves', 'there', 'under', \"you'd\", 'than', 'him', 'them', 'yourselves', 'and', 'no', \n",
    "         'same', 'whom', 'through', 'again', 'haven', 'an', 'some', 'nor', 'she', '&amp;', \"i'll\",\n",
    "         'while', 'at', 'further', 'out', \"wasn't\", 'himself', 'which', \"didn't\", 'am', \"shouldn't\", \n",
    "         'theirs', 'are', 'his', 'doing', 'it', 'that', 'me', \"weren't\", 'does', \"hasn't\", \n",
    "         'most', 'down', \"shouldn't\", 'more', \"hadn't\", 'why', \"aren't\", 'have', 'then', \"mustn't\", \n",
    "         'during', 're', \"didn't\", 'when', 'to', 'on', \"don't\", \"shan't\", 'did', 'its', 'a', 'in', \n",
    "         'own', 'off', 'itself', \"wouldn't\", 'such', 'can', 'each', 'yours', 'is', 'against', \n",
    "         'between', 'for', 'what', \"she's\", 'i', \"you'll\", 'here', \"couldn't\", 'above', 'from', \n",
    "         'if', 'you', 'other', 'who', 'but', \"mightn't\", 'those', 'he', 'not', 'once', 'how', 'too', \n",
    "         'this', 'were', 'very', 'been', \"you're\", 'be', 'or', 'now', \"you've\", 'the', 'until', \n",
    "         'having', 'only', 'their', 'of', 'should', 'had', \"isn't\", 'below', \"doesn't\", \"won't\", \n",
    "         'herself', 'just', 'her', \"i've\", \"i'm\"}\n",
    "\n",
    "\n",
    "print(len(stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "524afa1c-112b-49ce-8a05-d8508fe93b62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def convert_emoji_to_text(emoji_text):\n",
    "    text_with_aliases = emoji.demojize(emoji_text)\n",
    "    return text_with_aliases\n",
    "\n",
    "def clean_tweet(tweet:str) -> str:\n",
    "\n",
    "    converted_text = convert_emoji_to_text(tweet)\n",
    "    \n",
    "    # remove links and make lowercase\n",
    "    clean_tweet = re.sub(r'(www|http)\\S*', '', converted_text).lower()\n",
    "    clean_tweet = re.sub(r'_|:|-', ' ',clean_tweet)\n",
    "\n",
    "    # replace â€™ char with ' char\n",
    "    clean_tweet = re.sub(r'â€™', \"'\", clean_tweet)\n",
    "\n",
    "    # if words are present in stop words set then remove\n",
    "    word_tokens = clean_tweet.split(' ')\n",
    "    filtered_words = [word for word in word_tokens if not word in stops]\n",
    "\n",
    "    clean_tweet = \" \".join(filtered_words)\n",
    "    \n",
    "    # remove twitt handles, non-unicode chars, elipsis, & front slash\n",
    "    clean_tweet = re.sub(r'(@[\\S]*|[^\\x00-\\x7F]+|\\.+|\\/)', ' ', clean_tweet)\n",
    "  \n",
    "    # remove remaining punctuation and any non letter characters\n",
    "    clean_tweet = re.sub(r'[^a-z\\s]+', '', clean_tweet)\n",
    "    \n",
    "    # stemming words\n",
    "    stemmer = PorterStemmer()\n",
    "    clean_tweet = [stemmer.stem(word) for word in clean_tweet]\n",
    "    clean_tweet = ''.join(clean_tweet)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    clean_tweet = re.sub(r'\\s+', ' ', clean_tweet)\n",
    "    \n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0e9f58a8-c6ae-476e-8540-bc2f72dac3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets \n",
    "tweets_df['clean_tweets'] = tweets_df['text'].apply(clean_tweet)\n",
    "# tweets_df['clean_tweets'] = tweets_df.iloc[:,5].apply(clean_tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c36548f1-d661-46bc-88fc-199e9acadb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AmericanAir hi my flight to DFW 2463 was Cancelled Flightled tonight. Called in and left my number for call back it's been 3hrs please help.\n",
      " hi flight dfw cancelled flightled tonight called left number call back hrs please help \n",
      "\n",
      "\n",
      "@JetBlue true. Maybe. Wish I had expedited security haha\n",
      " true maybe wish expedited security haha\n",
      "\n",
      "\n",
      "@AmericanAir would it be possible to change my flight on your website? Many thanks\n",
      " would possible change flight website many thanks\n",
      "\n",
      "\n",
      "@SouthwestAir why are flights still getting out of Logan now? You couldn't manage to get one out at 6 AM, when it wasn't snowing!\n",
      " flights still getting logan now manage get one am snowing\n",
      "\n",
      "\n",
      "@VirginAmerica was wondering if you guys recieved my dm and we're able to potentially respond asap\n",
      " wondering guys recieved dm able potentially respond asap\n",
      "\n",
      "\n",
      "@SouthwestAir has the winner for #DestinationDragons been announced yet? If not when will they be??\n",
      " winner destinationdragons announced yet be\n",
      "\n",
      "\n",
      "@united I canâ€™t go back to the airport, Iâ€™m working, and wonâ€™t have time.  Are you telling me there is seriously no other way?\n",
      " cant go back airport working time telling seriously way\n",
      "\n",
      "\n",
      "@jetblue any idea where the plane for flight 672 is coming from? I thought flight 305 from JFK but that wouldn't explain delay.\n",
      " idea plane flight coming from thought flight jfk explain delay \n",
      "\n",
      "\n",
      "@united each flight is worse than last! flight attendants don't even know whether the plane is equipped with power outlets at the seats!\n",
      " flight worse last flight attendants even know whether plane equipped power outlets seats\n",
      "\n",
      "\n",
      "@SouthwestAir Why do you have to be 18 ðŸ˜­\n",
      " loudly crying face \n",
      "\n",
      "\n",
      "November 19 is #NationalDayofMonaco. Did you know that @AeroportNice serves the Principality of Monaco? Beginning 5/6/24, you can discover Monaco with https://t.co/s0jk5HxcQZ @americanair's nonstop flights from #PHLAirport to Nice. \n",
      "november nationaldayofmonaco know serves principality monaco beginning discover monaco nonstop flights phlairport nice \n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random_indices = random.sample(range(len(tweets_df)), 10)\n",
    "\n",
    "# check random tweets before/after cleaning\n",
    "for i in random_indices:\n",
    "    print(tweets_df['text'][i])\n",
    "    print(tweets_df['clean_tweets'][i])\n",
    "    print('\\n')\n",
    "\n",
    "twitt = \"November 19 is #NationalDayofMonaco. Did you know that @AeroportNice serves the Principality of Monaco? Beginning 5/6/24, you can discover Monaco with https://t.co/s0jk5HxcQZ @americanair's nonstop flights from #PHLAirport to Nice. \"\n",
    "clean_twitt = clean_tweet2(twitt)\n",
    "print(twitt)\n",
    "print(clean_twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a22d2de6-3329-4838-93fd-6d4b0a7081d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save dataframe to new csv file\n",
    "tweets_df.to_csv('data/clean_tweets_v2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1511fa-52d1-42b8-8bbb-18ba3128f3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
